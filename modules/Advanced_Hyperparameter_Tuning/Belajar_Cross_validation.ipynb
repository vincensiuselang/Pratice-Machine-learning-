{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kita mulai praktek dari K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ›  Contoh: K-Fold CV untuk Regresi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per fold: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
      "Mean Accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Inisialisasi model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# K-Fold Cross-Validation (misal, K=5)\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Cetak hasil\n",
    "print(f\"Accuracy per fold: {scores}\")\n",
    "print(f\"Mean Accuracy: {scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›  Contoh: K-Fold CV untuk Regresi\n",
    "#### Kita pakai dataset diabetes dari sklearn.datasets dan model Random Forest Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE per fold: [-3006.94880562 -3065.96508315 -3571.39149545 -3405.32815227\n",
      " -3804.19287614]\n",
      "Mean MSE: -3370.7653\n",
      "RMSE per fold: [54.83565269 55.3711575  59.76112027 58.35518959 61.67813937]\n",
      "Mean RMSE: 58.0003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# Inisialisasi model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Definisikan scoring metric (pakai negatif MSE karena cross_val_score meminimalkan skor)\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# K-Fold Cross-Validation (misal, K=5)\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring=mse_scorer)\n",
    "\n",
    "# Cetak hasil\n",
    "print(f\"MSE per fold: {scores}\")\n",
    "print(f\"Mean MSE: {scores.mean():.4f}\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(f\"RMSE per fold: {rmse_scores}\")\n",
    "print(f\"Mean RMSE: {rmse_scores.mean():.4f}\")\n",
    "\n",
    "# ğŸ” Analisis Hasil\n",
    "# 1ï¸âƒ£ RMSE lebih interpretatif dibanding MSE karena skalanya sama dengan target aslinya.\n",
    "# 2ï¸âƒ£ Variasi antar fold cukup kecil, berarti model kita cukup konsisten.\n",
    "# 3ï¸âƒ£ Kalau mau hasil lebih bagus, bisa coba hyperparameter tuning atau feature engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per fold: [0.96666667 0.96666667 0.93333333 0.96666667 0.9       ]\n",
      "Mean Accuracy: 0.9467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Inisialisasi model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Inisialisasi Stratified K-Fold (K=5)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluasi model dengan Stratified K-Fold\n",
    "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "# Cetak hasil\n",
    "print(f\"Accuracy per fold: {scores}\")\n",
    "print(f\"Mean Accuracy: {scores.mean():.4f}\")\n",
    "\n",
    "# ğŸ” Analisis Hasil\n",
    "# 1ï¸âƒ£ Variasi antar fold kecil â†’ Model kita stabil dan tidak overfitting ke satu fold tertentu.\n",
    "# 2ï¸âƒ£ Akurasi tinggi â†’ Random Forest cocok untuk dataset Iris, yang relatif seimbang dan tidak terlalu kompleks.\n",
    "# 3ï¸âƒ£ Stratified K-Fold membantu memastikan distribusi kelas tetap seimbang di setiap fold, sehingga model lebih adil dalam belajar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold untuk regresi\n",
    "\n",
    "#### ğŸ”¹ Bagaimana Cara Adaptasi Stratified K-Fold ke Regresi?\n",
    "#### 1ï¸âƒ£ Binning target variable â†’ Ubah nilai target kontinu menjadi kategori (misal, bagi jadi 5 kelompok berdasarkan kuantil).\n",
    "#### 2ï¸âƒ£ Gunakan Stratified K-Fold dengan kategori tersebut untuk menjaga distribusi target tetap seimbang di tiap fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\formylife\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE per fold: [-3235.2827382  -3015.34030449 -4041.1152625  -3844.60083523\n",
      " -2950.03258864]\n",
      "Mean MSE: -3417.2743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# Konversi target kontinu menjadi kategori dengan binning (misal, 5 bins)\n",
    "y_binned = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile').fit_transform(y.reshape(-1,1)).ravel()\n",
    "\n",
    "# Inisialisasi model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Inisialisasi Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Definisikan scoring metric (pakai negatif MSE karena cross_val_score meminimalkan skor)\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Evaluasi model\n",
    "scores = cross_val_score(model, X, y, cv=skf, scoring=mse_scorer)\n",
    "\n",
    "# Cetak hasil\n",
    "print(f\"MSE per fold: {scores}\")\n",
    "print(f\"Mean MSE: {scores.mean():.4f}\")\n",
    "\n",
    "# ğŸ” Analisis Hasil\n",
    "# âš  Warning: \"Least populated class in y has only 1 member\"\n",
    "# ğŸ”¹ Artinya, saat kita membagi target ke dalam 5 kategori, ada satu kategori yang cuma punya 1 data point, jadi sulit untuk dibagi ke dalam 5 fold.\n",
    "# ğŸ”¹ Solusi?\n",
    "# âœ… Kurangi jumlah bins jadi misalnya 3 atau 4 (karena datasetnya kecil).\n",
    "# âœ… Pakai metode K-Fold biasa kalau datasetnya tidak cocok untuk binning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ğŸ”¹ Apa Itu Time Series Split?\n",
    "#### ğŸ”¹ Berbeda dengan K-Fold biasa, karena data dibagi secara berurutan (bukan acak).\n",
    "#### ğŸ”¹ Digunakan untuk data berbasis waktu, misalnya prediksi harga saham, suhu, atau penjualan harian.\n",
    "#### ğŸ”¹ Setiap fold lebih besar dari fold sebelumnya, karena model tidak boleh \"melihat masa depan\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¹ Time Series Split untuk Klasifikasi\n",
    "#### Meskipun Time Series Split lebih sering dipakai di regresi (misal, harga saham, cuaca, dll.), kita bisa pakai untuk klasifikasi berbasis waktu, misalnya:\n",
    "#### âœ… Prediksi churn pelanggan (berdasarkan aktivitas sebelumnya).\n",
    "#### âœ… Prediksi kredit macet (berdasarkan riwayat transaksi).\n",
    "#### âœ… Deteksi penipuan (fraud detection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per fold: [1.  0.  1.  0.  0.8]\n",
      "Mean Accuracy: 0.5600\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Inisialisasi model (Decision Tree lebih toleran terhadap class imbalance)\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Inisialisasi Time Series Split (K=5)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Definisikan scoring metric (Accuracy)\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Evaluasi model dengan Time Series Split\n",
    "scores = cross_val_score(model, X, y, cv=tscv, scoring=accuracy_scorer)\n",
    "\n",
    "# Cetak hasil\n",
    "print(f\"Accuracy per fold: {scores}\")\n",
    "print(f\"Mean Accuracy: {scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Split untuk regresi\n",
    "#### ğŸ”¹ Langkah-langkah\n",
    "#### 1ï¸âƒ£ Gunakan dataset time-series, misalnya dataset Diabetes dari Scikit-Learn.\n",
    "#### 2ï¸âƒ£ Bagi data dengan TimeSeriesSplit (tanpa shuffle).\n",
    "#### 3ï¸âƒ£ Latih model regresi (Linear Regression).\n",
    "#### 4ï¸âƒ£ Evaluasi performa dengan MSE dan RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE per fold: [-3865.02037348 -3656.75210602 -3192.21541771 -3091.5807308\n",
      " -2459.86963436]\n",
      "Mean MSE: -3253.0877\n",
      "RMSE per fold: [62.16928802 60.47108488 56.49969396 55.60198495 49.59707284]\n",
      "Mean RMSE: 56.8678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset Diabetes (cocok untuk regresi)\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# Inisialisasi model Linear Regression\n",
    "model = LinearRegression()\n",
    "\n",
    "# Inisialisasi Time Series Split (5 fold)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Definisikan scoring metric (MSE)\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Evaluasi model dengan Time Series Split\n",
    "mse_scores = cross_val_score(model, X, y, cv=tscv, scoring=mse_scorer)\n",
    "\n",
    "# Hitung RMSE\n",
    "rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "# Cetak hasil\n",
    "print(f\"MSE per fold: {mse_scores}\")\n",
    "print(f\"Mean MSE: {mse_scores.mean():.4f}\")\n",
    "print(f\"RMSE per fold: {rmse_scores}\")\n",
    "print(f\"Mean RMSE: {rmse_scores.mean():.4f}\")\n",
    "\n",
    "# ğŸ“Š Analisis Hasil\n",
    "# ğŸ”¹ MSE per Fold â†’ Skor semakin kecil di fold terakhir (-2459.87), menunjukkan error lebih kecil seiring bertambahnya data.\n",
    "# ğŸ”¹ RMSE per Fold â†’ Turun dari 62.16 ke 49.59, artinya model makin baik dalam memprediksi pada fold terakhir.\n",
    "# ğŸ”¹ Mean RMSE = 56.87 â†’ Model cukup stabil, tapi masih bisa ditingkatkan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-One-Out Cross-Validation (LOOCV).\n",
    "## ğŸ”¹ Kita Mulai dengan Regresi Dulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 3001.7528\n",
      "Mean RMSE: 54.7883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset Diabetes\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# Inisialisasi model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Inisialisasi LOOCV\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Simpan hasil MSE\n",
    "mse_scores = []\n",
    "\n",
    "# Looping untuk setiap iterasi LOOCV\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Latih model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediksi\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Hitung MSE\n",
    "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Hitung rata-rata MSE & RMSE\n",
    "mean_mse = np.mean(mse_scores)\n",
    "mean_rmse = np.sqrt(mean_mse)\n",
    "\n",
    "# Cetak hasil\n",
    "print(f\"Mean MSE: {mean_mse:.4f}\")\n",
    "print(f\"Mean RMSE: {mean_rmse:.4f}\")\n",
    "\n",
    "# ğŸ“Š Analisis Hasil LOOCV\n",
    "# ğŸ”¹ Mean MSE: 3001.75 â†’ Lebih rendah dibanding Time Series Split (3253.09), yang berarti model lebih stabil.\n",
    "# ğŸ”¹ Mean RMSE: 54.79 â†’ Sedikit lebih kecil dibanding sebelumnya (56.86), menunjukkan prediksi sedikit lebih akurat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ“Œ Kesimpulan:\n",
    "#### âœ… LOOCV memanfaatkan hampir seluruh data untuk training, jadi hasilnya lebih stabil.\n",
    "#### âœ… Tetapi, prosesnya lebih lama & computationally expensive.\n",
    "#### âœ… Model ini masih bisa ditingkatkan dengan Feature Engineering atau Model Tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Cross-Validation\n",
    "## ğŸ”¹ Implementasi Nested CV untuk Regresi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE (Nested CV): 3013.8106\n",
      "Mean RMSE (Nested CV): 54.8982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# Outer Loop: 5-Fold Cross-Validation\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Ridge Regression dengan GridSearchCV di Inner Loop\n",
    "param_grid = {\"alpha\": [0.1, 1, 10, 100]}  # Hyperparameter Ridge\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)  # Inner Loop\n",
    "\n",
    "# Model dengan GridSearchCV\n",
    "model = GridSearchCV(Ridge(), param_grid, cv=inner_cv, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Evaluasi Nested Cross-Validation\n",
    "nested_scores = cross_val_score(model, X, y, cv=outer_cv, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Hitung rata-rata MSE & RMSE\n",
    "mean_mse = -np.mean(nested_scores)\n",
    "mean_rmse = np.sqrt(mean_mse)\n",
    "\n",
    "# Cetak hasil\n",
    "print(f\"Mean MSE (Nested CV): {mean_mse:.4f}\")\n",
    "print(f\"Mean RMSE (Nested CV): {mean_rmse:.4f}\")\n",
    "\n",
    "# ğŸ”¥ Nice! Hasilnya udah keluar!\n",
    "# ğŸ“Š Analisis Hasil Nested Cross-Validation:\n",
    "# ğŸ”¹ Mean MSE: 3013.81 â†’ Hampir sama dengan LOOCV (3001.75), yang berarti model cukup stabil.\n",
    "# ğŸ”¹ Mean RMSE: 54.90 â†’ Sedikit lebih tinggi dari LOOCV (54.79), tapi perbedaannya kecil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Kesimpulan:\n",
    "#### âœ… Nested CV memberikan estimasi performa yang lebih akurat karena sudah menghindari data leakage dari tuning hyperparameter.\n",
    "#### âœ… Performanya mirip dengan LOOCV, tapi Nested CV lebih efisien dalam pemrosesan dibanding LOOCV yang sangat berat.\n",
    "#### âœ… Model Ridge Regression sudah cukup baik, tapi masih bisa ditingkatkan dengan tuning lebih lanjut (misalnya pakai RandomizedSearchCV atau Bayesian Optimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¹ Implementasi Nested Cross-Validation untuk Klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (Nested CV): 0.9733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Outer Loop: 5-Fold Cross-Validation\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning dengan GridSearchCV di Inner Loop\n",
    "param_grid = {\"C\": [0.01, 0.1, 1, 10, 100]}  # Regularization parameter\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Model dengan GridSearchCV\n",
    "model = GridSearchCV(LogisticRegression(max_iter=2000), param_grid, cv=inner_cv, scoring='accuracy')\n",
    "\n",
    "# Evaluasi Nested Cross-Validation\n",
    "nested_scores = cross_val_score(model, X, y, cv=outer_cv, scoring='accuracy')\n",
    "\n",
    "# Hitung rata-rata akurasi\n",
    "mean_accuracy = np.mean(nested_scores)\n",
    "\n",
    "# Cetak hasil\n",
    "print(f\"Mean Accuracy (Nested CV): {mean_accuracy:.4f}\")\n",
    "\n",
    "# ğŸ“Š Analisis Hasil:\n",
    "# ğŸ”¹ Mean Accuracy (Nested CV): 0.9733 (97.33%) â†’ Model Logistic Regression dengan GridSearchCV bekerja sangat baik untuk dataset Iris.\n",
    "# ğŸ”¹ Tuning Hyperparameter dengan Nested CV â†’ Mengurangi risiko data leakage, sehingga estimasi performa lebih realistis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Kesimpulan:\n",
    "#### âœ… Model kita udah optimal â†’ Akurasi 97.33% itu udah sangat bagus buat dataset ini.\n",
    "#### âœ… Nested CV validasi hyperparameter dengan aman, karena memisahkan training-validation di dalam inner loop, lalu evaluasi final di outer loop.\n",
    "#### âœ… Tuning dengan GridSearchCV efektif, tapi bisa dicoba RandomizedSearchCV atau Optuna untuk eksperimen lebih luas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_ml)",
   "language": "python",
   "name": "env_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
